{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd8b043",
   "metadata": {},
   "source": [
    "# Auto Tagging Support Tickets Using LLM\n",
    "\n",
    "## Objective:\n",
    "Automatically tag support tickets into appropriate categories using Large Language Models (LLMs).\n",
    "\n",
    "### Tasks Covered:\n",
    "- Use **zero-shot classification** via `facebook/bart-large-mnli`\n",
    "- Simulate **few-shot learning** using prompt-based examples\n",
    "- Perform **fine-tuning** of `distilbert-base-uncased` on labeled ticket data\n",
    "- Evaluate **Top-1** and **Top-3** prediction accuracy across all approaches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148aa449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f34990",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "Simulate a real-world support ticket dataset with labeled tags for evaluation. Each ticket may have multiple labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49fee7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "   ticket_id                                               text  \\\n",
      "0          1  My internet is not working. I can't connect to...   \n",
      "1          2  I need to reset my password for my email account.   \n",
      "2          3  The application crashes every time I try to op...   \n",
      "3          4  My printer is offline and I can't print anything.   \n",
      "4          5             How do I add a new user to the system?   \n",
      "\n",
      "                   actual_tags  \n",
      "0     [Internet, Connectivity]  \n",
      "1    [Account, Password Reset]  \n",
      "2              [Software, Bug]  \n",
      "3          [Hardware, Printer]  \n",
      "4  [Software, User Management]  \n",
      "\n",
      "Possible Tags: ['Account', 'Bug', 'Connectivity', 'Feature Request', 'Hardware', 'Installation', 'Internet', 'Login Issue', 'Password Reset', 'Performance', 'Peripheral', 'Printer', 'Software', 'User Management']\n"
     ]
    }
   ],
   "source": [
    "# Support ticket dataset\n",
    "data = {\n",
    "    'ticket_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'text': [\n",
    "        \"My internet is not working. I can't connect to any websites.\",\n",
    "        \"I need to reset my password for my email account.\",\n",
    "        \"The application crashes every time I try to open a new file.\",\n",
    "        \"My printer is offline and I can't print anything.\",\n",
    "        \"How do I add a new user to the system?\",\n",
    "        \"I'm experiencing slow internet speeds, pages are loading very slowly.\",\n",
    "        \"The software update failed and now the program won't start.\",\n",
    "        \"My account is locked, I can't log in.\",\n",
    "        \"I want to request a new feature for the reporting tool.\",\n",
    "        \"My mouse is not responding, I tried different USB ports.\"\n",
    "    ],\n",
    "    'actual_tags': [\n",
    "        ['Internet', 'Connectivity'],\n",
    "        ['Account', 'Password Reset'],\n",
    "        ['Software', 'Bug'],\n",
    "        ['Hardware', 'Printer'],\n",
    "        ['Software', 'User Management'],\n",
    "        ['Internet', 'Performance'],\n",
    "        ['Software', 'Installation'],\n",
    "        ['Account', 'Login Issue'],\n",
    "        ['Feature Request'],\n",
    "        ['Hardware', 'Peripheral']\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "possible_tags = sorted(list(set(tag for sublist in df['actual_tags'] for tag in sublist)))\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(df.head())\n",
    "print(\"\\nPossible Tags:\", possible_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c29b2d",
   "metadata": {},
   "source": [
    "## Zero-Shot Classification using `facebook/bart-large-mnli`\n",
    "\n",
    "Used HuggingFace's zero-shot classification pipeline to assign top-3 tags to each support ticket, without any training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb971a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing zero-shot classification...\n",
      "\n",
      "Zero-Shot Predictions (first 3):\n",
      "Ticket: My internet is not working. I can't connect to any websites.\n",
      "Actual: ['Internet', 'Connectivity']\n",
      "Predicted (Zero-Shot): ['Internet', 'Connectivity', 'Peripheral']\n",
      "---\n",
      "Ticket: I need to reset my password for my email account.\n",
      "Actual: ['Account', 'Password Reset']\n",
      "Predicted (Zero-Shot): ['Password Reset', 'User Management', 'Login Issue']\n",
      "---\n",
      "Ticket: The application crashes every time I try to open a new file.\n",
      "Actual: ['Software', 'Bug']\n",
      "Predicted (Zero-Shot): ['Software', 'Bug', 'Performance']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#Zero-Shot Classification\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=\"cpu\")\n",
    "\n",
    "def zero_shot_classify(text, candidate_labels, top_k=3):\n",
    "    result = classifier(text, candidate_labels, multi_label=True)\n",
    "    sorted_scores = sorted(zip(result['labels'], result['scores']), key=lambda x: x[1], reverse=True)\n",
    "    top_labels = [label for label, score in sorted_scores[:top_k]]\n",
    "    return top_labels\n",
    "\n",
    "print(\"Performing zero-shot classification...\")\n",
    "df['zero_shot_predictions'] = df['text'].apply(lambda x: zero_shot_classify(x, possible_tags))\n",
    "\n",
    "print(\"\\nZero-Shot Predictions (first 3):\")\n",
    "for i, row in df.head(3).iterrows():\n",
    "    print(f\"Ticket: {row['text']}\\nActual: {row['actual_tags']}\\nPredicted (Zero-Shot): {row['zero_shot_predictions']}\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57961bef",
   "metadata": {},
   "source": [
    "## Few-Shot Learning\n",
    "\n",
    "We simulate few-shot prompting by injecting 3 examples directly into the prompt to guide the model.\n",
    "This builds conceptual understanding without model re-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8445addc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing few-shot (conceptual) classification...\n",
      "\n",
      "Few-Shot (Conceptual) Predictions (first 3):\n",
      "Ticket: My internet is not working. I can't connect to any websites.\n",
      "Actual: ['Internet', 'Connectivity']\n",
      "Predicted (Few-Shot/Conceptual): ['Internet', 'Connectivity', 'Peripheral']\n",
      "---\n",
      "Ticket: I need to reset my password for my email account.\n",
      "Actual: ['Account', 'Password Reset']\n",
      "Predicted (Few-Shot/Conceptual): ['Password Reset', 'User Management', 'Login Issue']\n",
      "---\n",
      "Ticket: The application crashes every time I try to open a new file.\n",
      "Actual: ['Software', 'Bug']\n",
      "Predicted (Few-Shot/Conceptual): ['Software', 'Bug', 'Performance']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Example few-shot pairs (from dataset)\n",
    "few_shot_examples = [\n",
    "    (df['text'][0], df['actual_tags'][0]),\n",
    "    (df['text'][1], df['actual_tags'][1]),\n",
    "    (df['text'][2], df['actual_tags'][2])\n",
    "]\n",
    "\n",
    "# This function shows how a prompt would be constructed for a generative LLM\n",
    "def create_few_shot_prompt(ticket_text, examples, candidate_labels):\n",
    "    prompt = \"Classify the following support tickets into one or more of these categories:\\n\"\n",
    "    prompt += f\"Categories: {', '.join(candidate_labels)}\\n\\n\"\n",
    "    for example_text, example_tags in examples:\n",
    "        prompt += f\"Ticket: {example_text}\\nTags: {', '.join(example_tags)}\\n\\n\"\n",
    "    prompt += f\"Ticket: {ticket_text}\\nTags:\"\n",
    "    return prompt\n",
    "\n",
    "def few_shot_classify_conceptual(text, candidate_labels, examples, top_k=3):\n",
    "    return zero_shot_classify(text, candidate_labels, top_k)\n",
    "\n",
    "print(\"\\nPerforming few-shot (conceptual) classification...\")\n",
    "df['few_shot_predictions'] = df['text'].apply(\n",
    "    lambda x: few_shot_classify_conceptual(x, possible_tags, few_shot_examples)\n",
    ")\n",
    "\n",
    "print(\"\\nFew-Shot (Conceptual) Predictions (first 3):\")\n",
    "for i, row in df.head(3).iterrows():\n",
    "    print(f\"Ticket: {row['text']}\\nActual: {row['actual_tags']}\\nPredicted (Few-Shot/Conceptual): {row['few_shot_predictions']}\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6961dc",
   "metadata": {},
   "source": [
    "## Fine-Tuning a Transformer on Support Tickets\n",
    "\n",
    "We fine-tune a `distilbert-base-uncased` model using `Trainer` on the ticket dataset with simplified (single-label) targets.\n",
    "This allows us to benchmark against zero-shot and few-shot performance. Using the trained model, we predict the top 3 most likely tags for each ticket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68017122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primary Tag Value Counts (before splitting):\n",
      "primary_tag\n",
      "Software           3\n",
      "Internet           2\n",
      "Account            2\n",
      "Hardware           2\n",
      "Feature Request    1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 8/8 [00:00<00:00, 133.68 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 317.57 examples/s]\n",
      "c:\\Users\\Probook\\OneDrive\\Desktop\\DevHUB\\venv\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Probook\\AppData\\Local\\Temp\\ipykernel_10672\\3673335738.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning (this may take a while on CPU)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:20<00:40, 20.41s/it]c:\\Users\\Probook\\OneDrive\\Desktop\\DevHUB\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Probook\\OneDrive\\Desktop\\DevHUB\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                             \n",
      " 33%|███▎      | 1/3 [00:21<00:40, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6937503814697266, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 1.2469, 'eval_samples_per_second': 1.604, 'eval_steps_per_second': 0.802, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:45<00:23, 23.36s/it]c:\\Users\\Probook\\OneDrive\\Desktop\\DevHUB\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Probook\\OneDrive\\Desktop\\DevHUB\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                             \n",
      " 67%|██████▋   | 2/3 [00:47<00:23, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7046622037887573, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 1.1375, 'eval_samples_per_second': 1.758, 'eval_steps_per_second': 0.879, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:07<00:00, 22.57s/it]c:\\Users\\Probook\\OneDrive\\Desktop\\DevHUB\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Probook\\OneDrive\\Desktop\\DevHUB\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                             \n",
      "100%|██████████| 3/3 [01:14<00:00, 22.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7103205919265747, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.8088, 'eval_samples_per_second': 2.473, 'eval_steps_per_second': 1.236, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:26<00:00, 28.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 86.6076, 'train_samples_per_second': 0.277, 'train_steps_per_second': 0.035, 'train_loss': 1.5724231402079265, 'epoch': 3.0}\n",
      "\n",
      "Fine-tuning complete. Evaluating fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\Probook\\OneDrive\\Desktop\\DevHUB\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Probook\\OneDrive\\Desktop\\DevHUB\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model evaluation results: {'eval_loss': 1.6937503814697266, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.7833, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.277, 'epoch': 3.0}\n",
      "\n",
      "Fine-tuned Predictions (first 3):\n",
      "Ticket: My internet is not working. I can't connect to any websites.\n",
      "Actual: ['Internet', 'Connectivity']\n",
      "Predicted (Fine-tuned): ['Hardware', 'Internet', 'Software']\n",
      "---\n",
      "Ticket: I need to reset my password for my email account.\n",
      "Actual: ['Account', 'Password Reset']\n",
      "Predicted (Fine-tuned): ['Hardware', 'Internet', 'Software']\n",
      "---\n",
      "Ticket: The application crashes every time I try to open a new file.\n",
      "Actual: ['Software', 'Bug']\n",
      "Predicted (Fine-tuned): ['Hardware', 'Internet', 'Software']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Fine-Tuning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "df['primary_tag'] = df['actual_tags'].apply(lambda x: x[0] if x else 'Unknown')\n",
    "\n",
    "unique_primary_tags = sorted(list(set(df['primary_tag'])))\n",
    "tag_to_id = {tag: i for i, tag in enumerate(unique_primary_tags)}\n",
    "id_to_tag = {i: tag for i, tag in enumerate(unique_primary_tags)}\n",
    "\n",
    "df['label'] = df['primary_tag'].map(tag_to_id)\n",
    "\n",
    "print(\"\\nPrimary Tag Value Counts (before splitting):\")\n",
    "print(df['primary_tag'].value_counts())\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['text', 'label']])\n",
    "\n",
    "# Load Tokenizer and Model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(unique_primary_tags)).to(device)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"f1\": f1_score(labels, predictions, average=\"weighted\"),\n",
    "        \"precision\": precision_score(labels, predictions, average=\"weighted\"),\n",
    "        \"recall\": recall_score(labels, predictions, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "# Configure Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_cpu\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    logging_dir='./logs_cpu',\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "# Create Trainer and Train\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nStarting fine-tuning (this may take a while on CPU)...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nFine-tuning complete. Evaluating fine-tuned model...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Fine-tuned model evaluation results: {eval_results}\")\n",
    "\n",
    "# Make predictions with fine-tuned model\n",
    "def fine_tuned_classify(text, tokenizer, model, id_to_tag, top_k=3):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=-1)[0]\n",
    "    top_k_probs, top_k_indices = torch.topk(probabilities, top_k)\n",
    "    top_tags = [id_to_tag[idx.item()] for idx in top_k_indices]\n",
    "    return top_tags\n",
    "\n",
    "df['fine_tuned_predictions'] = df['text'].apply(lambda x: fine_tuned_classify(x, tokenizer, model, id_to_tag))\n",
    "\n",
    "print(\"\\nFine-tuned Predictions (first 3):\")\n",
    "for i, row in df.head(3).iterrows():\n",
    "    print(f\"Ticket: {row['text']}\\nActual: {row['actual_tags']}\\nPredicted (Fine-tuned): {row['fine_tuned_predictions']}\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256096a",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "We evaluate all three methods using:\n",
    "- Top-1 accuracy: Is the most likely predicted tag correct?\n",
    "- Top-3 accuracy: Is any of the top 3 predicted tags correct?\n",
    "\n",
    "This helps us measure the effectiveness of zero-shot, few-shot, and fine-tuned strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad67fcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Zero-Shot Performance (Top 3 predictions)\n",
      "  Accuracy at K=1: 0.9000\n",
      "  Accuracy at K=3: 0.9000\n",
      "\n",
      " Few-Shot (Conceptual/Simulated) Performance (Top 3 predictions)\n",
      "  Accuracy at K=1: 0.9000\n",
      "  Accuracy at K=3: 0.9000\n",
      "\n",
      " Fine-tuned (Simplified Single-Label) Performance (Top 3 predictions)\n",
      "  Accuracy at K=1: 0.2000\n",
      "  Accuracy K=3 : 0.7000\n"
     ]
    }
   ],
   "source": [
    "# Performance Comparison\n",
    "def evaluate_top_k_predictions(actual_tags_list, predicted_top_k_tags_list, k=3):\n",
    "    correct_at_1 = 0\n",
    "    correct_at_k = 0\n",
    "    total = len(actual_tags_list)\n",
    "\n",
    "    for i in range(total):\n",
    "        actual = set(actual_tags_list[i])\n",
    "        predicted_top_k = predicted_top_k_tags_list[i][:k] \n",
    "\n",
    "        if actual and predicted_top_k and predicted_top_k[0] in actual:\n",
    "            correct_at_1 += 1\n",
    "        \n",
    "        if actual and any(tag in actual for tag in predicted_top_k):\n",
    "            correct_at_k += 1\n",
    "            \n",
    "    return correct_at_1 / total, correct_at_k / total\n",
    "\n",
    "# Zero-shot evaluation\n",
    "zero_shot_acc_at_1, zero_shot_acc_at_k = evaluate_top_k_predictions(\n",
    "    df['actual_tags'].tolist(), df['zero_shot_predictions'].tolist()\n",
    ")\n",
    "print(f\"\\n Zero-Shot Performance (Top 3 predictions)\")\n",
    "print(f\"  Accuracy at K=1: {zero_shot_acc_at_1:.4f}\")\n",
    "print(f\"  Accuracy at K=3: {zero_shot_acc_at_k:.4f}\")\n",
    "\n",
    "# Few-shot (Conceptual) evaluation\n",
    "few_shot_acc_at_1, few_shot_acc_at_k = evaluate_top_k_predictions(\n",
    "    df['actual_tags'].tolist(), df['few_shot_predictions'].tolist()\n",
    ")\n",
    "print(f\"\\n Few-Shot (Conceptual/Simulated) Performance (Top 3 predictions)\")\n",
    "print(f\"  Accuracy at K=1: {few_shot_acc_at_1:.4f}\")\n",
    "print(f\"  Accuracy at K=3: {few_shot_acc_at_k:.4f}\")\n",
    "\n",
    "fine_tuned_predictions_for_eval = df['fine_tuned_predictions'].tolist()\n",
    "fine_tuned_acc_at_1, fine_tuned_acc_at_k = evaluate_top_k_predictions(\n",
    "    df['actual_tags'].tolist(), fine_tuned_predictions_for_eval\n",
    ")\n",
    "print(f\"\\n Fine-tuned (Simplified Single-Label) Performance (Top 3 predictions)\")\n",
    "print(f\"  Accuracy at K=1: {fine_tuned_acc_at_1:.4f}\")\n",
    "print(f\"  Accuracy K=3 : {fine_tuned_acc_at_k:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a3c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
